[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gabriel Guzman",
    "section": "",
    "text": "Biology and Environmental Science undergraduate interested in Data Science and Data Analytics."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Gabriel Guzman",
    "section": "Education",
    "text": "Education\n Gettysburg College | Gettysburg, PA \nB.S in Biology | Aug 2020 - May 2024\nB.S in Environmental Studies | Aug 2020 - May 2024"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Gabriel Guzman",
    "section": "Experience",
    "text": "Experience"
  },
  {
    "objectID": "posts/titanic/index.html",
    "href": "posts/titanic/index.html",
    "title": "Titanic Survival A Machine Learning Based Analysis",
    "section": "",
    "text": "Titanic Survival: A Machine Learning based Analysis\nBased on Kaggle’s ‘Titanic - Machine Learning from Disaster’ Machine Learning Competition (https://www.kaggle.com/competitions/titanic/data)\n\n#---Installing Libraries---#\nimport numpy as np \nimport pandas as pd\n\n\n#---Loading Data---#\n\ntrain_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\ntest_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\n\n#---Exploratory Data Analysis---#\n\n# Summary of train data\ntest_data.describe()\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      count\n      891.000000\n      891.000000\n      891.000000\n      714.000000\n      891.000000\n      891.000000\n      891.000000\n    \n    \n      mean\n      446.000000\n      0.383838\n      2.308642\n      29.699118\n      0.523008\n      0.381594\n      32.204208\n    \n    \n      std\n      257.353842\n      0.486592\n      0.836071\n      14.526497\n      1.102743\n      0.806057\n      49.693429\n    \n    \n      min\n      1.000000\n      0.000000\n      1.000000\n      0.420000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      223.500000\n      0.000000\n      2.000000\n      20.125000\n      0.000000\n      0.000000\n      7.910400\n    \n    \n      50%\n      446.000000\n      0.000000\n      3.000000\n      28.000000\n      0.000000\n      0.000000\n      14.454200\n    \n    \n      75%\n      668.500000\n      1.000000\n      3.000000\n      38.000000\n      1.000000\n      0.000000\n      31.000000\n    \n    \n      max\n      891.000000\n      1.000000\n      3.000000\n      80.000000\n      8.000000\n      6.000000\n      512.329200\n    \n  \n\n\n\n\n\n# Women survived in train data \nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\nprint(\"% of women who survived:\", rate_women)\n\n# Men survived in train data \nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\nprint(\"% of men who survived:\", rate_men)\n\n% of women who survived: 0.7420382165605095\n% of men who survived: 0.18890814558058924\n\n\n\n# Machine Learning Model (Randoom Forest Algorithm)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions, 'Sex': test_data.Sex})\noutput.to_csv('submission.csv', index=False)\n\n\n# Female survived = 0.910828025 \n# Male survived = 0.010398614\n\n# % of women who survived: 0.7420382165605095\n# % of men who survived: 0.18890814558058924"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Ant Morphology Analysis\n\n\n\nData Analytics\n\n\nBiology\n\n\n\n\n\n\n\nGabriel Guzman, Alexis Jones, Anna Imrie, Aiden Ludka\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nButterfly Population Analysis\n\n\n\nData Science\n\n\nData Analytics\n\n\nBiology\n\n\n\n\n\n\n\nGabriel Guzman\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Intro to Data Science Presentation\n\n\n\nData Science\n\n\nData Analytics\n\n\nMachine Learning\n\n\n\n\n\n\n\nGabriel Guzman\n\n\nMar 2, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/titanic/index.html",
    "href": "projects/titanic/index.html",
    "title": "Titanic Survival A Machine Learning Based Analysis",
    "section": "",
    "text": "Titanic Survival: A Machine Learning based Analysis\nBased on Kaggle’s ‘Titanic - Machine Learning from Disaster’ Machine Learning Competition (https://www.kaggle.com/competitions/titanic/data)\n\n\nCode\n#---Installing Libraries---#\nimport numpy as np \nimport pandas as pd\n\n\n\n\nCode\n#---Loading Data---#\n\ntrain_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\ntest_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\n\n\n\nCode\n#---Exploratory Data Analysis---#\n\n# Summary of train data\ntest_data.describe()\n\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      count\n      891.000000\n      891.000000\n      891.000000\n      714.000000\n      891.000000\n      891.000000\n      891.000000\n    \n    \n      mean\n      446.000000\n      0.383838\n      2.308642\n      29.699118\n      0.523008\n      0.381594\n      32.204208\n    \n    \n      std\n      257.353842\n      0.486592\n      0.836071\n      14.526497\n      1.102743\n      0.806057\n      49.693429\n    \n    \n      min\n      1.000000\n      0.000000\n      1.000000\n      0.420000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      223.500000\n      0.000000\n      2.000000\n      20.125000\n      0.000000\n      0.000000\n      7.910400\n    \n    \n      50%\n      446.000000\n      0.000000\n      3.000000\n      28.000000\n      0.000000\n      0.000000\n      14.454200\n    \n    \n      75%\n      668.500000\n      1.000000\n      3.000000\n      38.000000\n      1.000000\n      0.000000\n      31.000000\n    \n    \n      max\n      891.000000\n      1.000000\n      3.000000\n      80.000000\n      8.000000\n      6.000000\n      512.329200\n    \n  \n\n\n\n\n\n\nCode\n# Women survived in train data \nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\nprint(\"% of women who survived:\", rate_women)\n\n# Men survived in train data \nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\nprint(\"% of men who survived:\", rate_men)\n\n\n% of women who survived: 0.7420382165605095\n% of men who survived: 0.18890814558058924\n\n\n\n\nCode\n# Machine Learning Model (Randoom Forest Algorithm)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions, 'Sex': test_data.Sex})\noutput.to_csv('submission.csv', index=False)\n\n\n\n\nCode\n# Female survived = 0.910828025 \n# Male survived = 0.010398614\n\n# % of women who survived: 0.7420382165605095\n# % of men who survived: 0.18890814558058924"
  },
  {
    "objectID": "blog-posts/titanic/index.html",
    "href": "blog-posts/titanic/index.html",
    "title": "Empty",
    "section": "",
    "text": "Titanic Survival: A Machine Learning based Analysis\nBased on Kaggle’s ‘Titanic - Machine Learning from Disaster’ Machine Learning Competition (https://www.kaggle.com/competitions/titanic/data)\n\n#---Installing Libraries---#\nimport numpy as np \nimport pandas as pd\n\n\n#---Loading Data---#\n\ntrain_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\ntest_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\n\n#---Exploratory Data Analysis---#\n\n# Summary of train data\ntest_data.describe()\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      count\n      891.000000\n      891.000000\n      891.000000\n      714.000000\n      891.000000\n      891.000000\n      891.000000\n    \n    \n      mean\n      446.000000\n      0.383838\n      2.308642\n      29.699118\n      0.523008\n      0.381594\n      32.204208\n    \n    \n      std\n      257.353842\n      0.486592\n      0.836071\n      14.526497\n      1.102743\n      0.806057\n      49.693429\n    \n    \n      min\n      1.000000\n      0.000000\n      1.000000\n      0.420000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      223.500000\n      0.000000\n      2.000000\n      20.125000\n      0.000000\n      0.000000\n      7.910400\n    \n    \n      50%\n      446.000000\n      0.000000\n      3.000000\n      28.000000\n      0.000000\n      0.000000\n      14.454200\n    \n    \n      75%\n      668.500000\n      1.000000\n      3.000000\n      38.000000\n      1.000000\n      0.000000\n      31.000000\n    \n    \n      max\n      891.000000\n      1.000000\n      3.000000\n      80.000000\n      8.000000\n      6.000000\n      512.329200\n    \n  \n\n\n\n\n\n# Women survived in train data \nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\nprint(\"% of women who survived:\", rate_women)\n\n# Men survived in train data \nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\nprint(\"% of men who survived:\", rate_men)\n\n% of women who survived: 0.7420382165605095\n% of men who survived: 0.18890814558058924\n\n\n\n# Machine Learning Model (Randoom Forest Algorithm)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions, 'Sex': test_data.Sex})\noutput.to_csv('submission.csv', index=False)\n\n\n# Female survived = 0.910828025 \n# Male survived = 0.010398614\n\n# % of women who survived: 0.7420382165605095\n# % of men who survived: 0.18890814558058924"
  },
  {
    "objectID": "projects/Lepidoptera in Gettysburg/index.html",
    "href": "projects/Lepidoptera in Gettysburg/index.html",
    "title": "Titanic Survival A Machine Learning Based Analysis",
    "section": "",
    "text": "Titanic Survival: A Machine Learning based Analysis\nBased on Kaggle’s ‘Titanic - Machine Learning from Disaster’ Machine Learning Competition (https://www.kaggle.com/competitions/titanic/data)\n\n\nCode\n#---Installing Libraries---#\nimport numpy as np \nimport pandas as pd\n\n\n\n\nCode\n#---Loading Data---#\n\ntrain_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\ntest_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\n\n\n\nCode\n#---Exploratory Data Analysis---#\n\n# Summary of train data\ntest_data.describe()\n\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      count\n      891.000000\n      891.000000\n      891.000000\n      714.000000\n      891.000000\n      891.000000\n      891.000000\n    \n    \n      mean\n      446.000000\n      0.383838\n      2.308642\n      29.699118\n      0.523008\n      0.381594\n      32.204208\n    \n    \n      std\n      257.353842\n      0.486592\n      0.836071\n      14.526497\n      1.102743\n      0.806057\n      49.693429\n    \n    \n      min\n      1.000000\n      0.000000\n      1.000000\n      0.420000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      223.500000\n      0.000000\n      2.000000\n      20.125000\n      0.000000\n      0.000000\n      7.910400\n    \n    \n      50%\n      446.000000\n      0.000000\n      3.000000\n      28.000000\n      0.000000\n      0.000000\n      14.454200\n    \n    \n      75%\n      668.500000\n      1.000000\n      3.000000\n      38.000000\n      1.000000\n      0.000000\n      31.000000\n    \n    \n      max\n      891.000000\n      1.000000\n      3.000000\n      80.000000\n      8.000000\n      6.000000\n      512.329200\n    \n  \n\n\n\n\n\n\nCode\n# Women survived in train data \nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\nprint(\"% of women who survived:\", rate_women)\n\n# Men survived in train data \nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\nprint(\"% of men who survived:\", rate_men)\n\n\n% of women who survived: 0.7420382165605095\n% of men who survived: 0.18890814558058924\n\n\n\n\nCode\n# Machine Learning Model (Randoom Forest Algorithm)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions, 'Sex': test_data.Sex})\noutput.to_csv('submission.csv', index=False)\n\n\n\n\nCode\n# Female survived = 0.910828025 \n# Male survived = 0.010398614\n\n# % of women who survived: 0.7420382165605095\n# % of men who survived: 0.18890814558058924"
  },
  {
    "objectID": "blog-posts/titanic-presentation/index.html",
    "href": "blog-posts/titanic-presentation/index.html",
    "title": "Intro to Data Science Presentation",
    "section": "",
    "text": "Titanic Survival: A Machine Learning Based Analysis\nData Science Presentation for Association of Computing Machinery.\nThe Association for Computing Machinery in Gettysburg College is a student-led organization where students from different disciplines and fields with interest in computer science gather to learn from each other and to form a community. For this week’s meeting, I will be giving a presentation on “Into to Data Science”, demonstrating the data science and data analytics workflow, from data exploration, hypothesis making, and modelling processes required to answer data-driven questions. This presentation is adapted from Kaggle’s ‘Titanic - Machine Learning from Disaster’ Machine Learning Competition (https://www.kaggle.com/competitions/titanic/data).\n\n#---Installing Libraries---#\nimport numpy as np \nimport pandas as pd\n\n\n#---Loading Data---#\n\ntrain_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\ntest_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\n\n#---Exploratory Data Analysis---#\n\n# Summary of train data\ntest_data.describe()\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      count\n      891.000000\n      891.000000\n      891.000000\n      714.000000\n      891.000000\n      891.000000\n      891.000000\n    \n    \n      mean\n      446.000000\n      0.383838\n      2.308642\n      29.699118\n      0.523008\n      0.381594\n      32.204208\n    \n    \n      std\n      257.353842\n      0.486592\n      0.836071\n      14.526497\n      1.102743\n      0.806057\n      49.693429\n    \n    \n      min\n      1.000000\n      0.000000\n      1.000000\n      0.420000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      223.500000\n      0.000000\n      2.000000\n      20.125000\n      0.000000\n      0.000000\n      7.910400\n    \n    \n      50%\n      446.000000\n      0.000000\n      3.000000\n      28.000000\n      0.000000\n      0.000000\n      14.454200\n    \n    \n      75%\n      668.500000\n      1.000000\n      3.000000\n      38.000000\n      1.000000\n      0.000000\n      31.000000\n    \n    \n      max\n      891.000000\n      1.000000\n      3.000000\n      80.000000\n      8.000000\n      6.000000\n      512.329200\n    \n  \n\n\n\n\n\n# Women survived in train data \nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\nprint(\"% of women who survived:\", rate_women)\n\n# Men survived in train data \nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\nprint(\"% of men who survived:\", rate_men)\n\n% of women who survived: 0.7420382165605095\n% of men who survived: 0.18890814558058924\n\n\n\n# Machine Learning Model (Randoom Forest Algorithm)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions, 'Sex': test_data.Sex})\noutput.to_csv('submission.csv', index=False)\n\n\n# Female survived = 0.910828025 \n# Male survived = 0.010398614\n\n# % of women who survived: 0.7420382165605095\n# % of men who survived: 0.18890814558058924"
  },
  {
    "objectID": "projects/lepidoptera-gettysburg/index.html",
    "href": "projects/lepidoptera-gettysburg/index.html",
    "title": "Butterfly Population Analysis",
    "section": "",
    "text": "Research Project on the change of local butterfly populations and relation to plant resources.\nThe insect apocalypse has\n\n\n\n\n\nThe Cross-Disciplinary Science Institute or X-SIG is a program offered by Gettyburg College for undergraduate students to work on mentored research projects with faculty from a variety of departments.\n\n\nRoyal Restoration of Regal Fritillary Habitat (and Other Easy-to-Pronounce Organisms)\n\n\n\nSugar Magnolia, Blossom Blooming, Heads All Empty and I Don’t Care"
  },
  {
    "objectID": "blog-posts/intro-to-data/index.html",
    "href": "blog-posts/intro-to-data/index.html",
    "title": "Intro to Data Science Presentation",
    "section": "",
    "text": "Data Science Presentation for Association of Computing Machinery\nDescription: Introductory data science presentation and project walkthrough with Gettysburg College students\n\n\nThe Association for Computing Machinery (ACM) in Gettysburg College is a student-led organization where students from different disciplines and fields with interest in computer science gather to learn from each other and to form a community on campus. For this week’s meeting, gave a presentation on “Into to Data Science”, demonstrating the data science and data analytics workflow, from data exploration, hypothesis testing, and modelling processes useful to answer data-driven questions. This presentation is adapted from Kaggle’s Titanic - Machine Learning from Disaster’ Machine Learning Competition.\n\n\n\n\n\n\n\n# Installing Libraries \n\nimport numpy as np # Numopy is a fundamental python library for scientific computation \nimport pandas as pd # Pandas provides fast data structures and data analysis tools for manipulating data in python\n\n\n# Loading Datasets\n\n# Titanic survival data is divided into two datasets: Train and Test\ntrain_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\ntest_data = pd.read_csv(\"/Users/gabrielguzman/School/Research/Data Science/titanic/train.csv\")\n\n\n#---Exploratory Data Analysis---#\n\n# Summary of train data\ntest_data.describe()\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      count\n      891.000000\n      891.000000\n      891.000000\n      714.000000\n      891.000000\n      891.000000\n      891.000000\n    \n    \n      mean\n      446.000000\n      0.383838\n      2.308642\n      29.699118\n      0.523008\n      0.381594\n      32.204208\n    \n    \n      std\n      257.353842\n      0.486592\n      0.836071\n      14.526497\n      1.102743\n      0.806057\n      49.693429\n    \n    \n      min\n      1.000000\n      0.000000\n      1.000000\n      0.420000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      223.500000\n      0.000000\n      2.000000\n      20.125000\n      0.000000\n      0.000000\n      7.910400\n    \n    \n      50%\n      446.000000\n      0.000000\n      3.000000\n      28.000000\n      0.000000\n      0.000000\n      14.454200\n    \n    \n      75%\n      668.500000\n      1.000000\n      3.000000\n      38.000000\n      1.000000\n      0.000000\n      31.000000\n    \n    \n      max\n      891.000000\n      1.000000\n      3.000000\n      80.000000\n      8.000000\n      6.000000\n      512.329200\n    \n  \n\n\n\n\n\n# Women survived in train data \nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\nprint(\"% of women who survived:\", rate_women)\n\n# Men survived in train data \nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\nprint(\"% of men who survived:\", rate_men)\n\n% of women who survived: 0.7420382165605095\n% of men who survived: 0.18890814558058924\n\n\n\n# Machine Learning Model (Randoom Forest Algorithm)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions, 'Sex': test_data.Sex})\noutput.to_csv('submission.csv', index=False)\n\n\n# Female survived = 0.910828025 \n# Male survived = 0.010398614\n\n# % of women who survived: 0.7420382165605095\n# % of men who survived: 0.18890814558058924"
  },
  {
    "objectID": "projects/ants-in-guadarrama/index.html",
    "href": "projects/ants-in-guadarrama/index.html",
    "title": "Ant Morphology Analysis",
    "section": "",
    "text": "Description: Statistical Analysis on the morphology and eating preference ants\n\n\nOur study took place in the Guadarra Mountains of Spain. Scientists measured the size of the different morphological structures of a multitude of ant genera across varying altitudes and regions of Guadarra mountain range as well as the resources ants were observed using. We aim to analyze how the size of the measured morphological features varies with altitude as well as to understand a genus-specific preference for certain resource types across ant taxa.\n\n\n\n\n\n\nThe data sets we used can be found here:\n‘Ant_traits_in_central_Spain’\n‘AntsInGuadarrama’\n\n# Install and Load Packages\n\n#Downloading all desired packages into local device\ninstall.packages (\"tidyverse\", repos = \"https://cran.rstudio.com\") #This package allows for simplified and more intuitive syntax in R \n\n\nThe downloaded binary packages are in\n    /var/folders/jm/8d66kd6x0qx0lyr8t1y3djg00000gn/T//RtmpQxPVfo/downloaded_packages\n\ninstall.packages (\"rstatix\", repos = \"https://cran.rstudio.com\") #This package allows for a variety of tests for statistical significance with the use of its integrated functions\n\n\nThe downloaded binary packages are in\n    /var/folders/jm/8d66kd6x0qx0lyr8t1y3djg00000gn/T//RtmpQxPVfo/downloaded_packages\n\ninstall.packages (\"ggplot2\", repos = \"https://cran.rstudio.com\") #This package allows for the \n\n\nThe downloaded binary packages are in\n    /var/folders/jm/8d66kd6x0qx0lyr8t1y3djg00000gn/T//RtmpQxPVfo/downloaded_packages\n\n#Loading all libraries into current R notebook\nlibrary (tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary (rstatix)\n\n\nAttaching package: 'rstatix'\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nlibrary (ggplot2)\n\n\n\n\n# Import Data + Create Dataframes\n\nAnt = read.csv(\"Ant_traits_in_central_Spain.csv\", header = TRUE) #Importing data set into R from local device for Hypothesis 1 \n\n# Result: Data in R environment, ready to be manipulated and tested for statistical significance \n\n\n# Data Summary Calculations\n\nhead_mean = mean(Ant$head) #Create data frame for the mean size of ant head\nprint(head_mean) #Output the value in 'head_mean', the mean size of the head\n\n[1] NA\n\nleg_mean = mean(Ant$leg) #Create data frame for the mean size of ant leg\nprint(leg_mean) #Output the value in 'leg_mean', the mean size of the leg\n\n[1] NA\n\nscape_mean = mean(Ant$scape) #Create data frame for the mean size of ant scape\nprint(scape_mean) #Output the value in 'scape_mean', the mean size of the scape\n\n[1] NA\n\neye_mean = mean(Ant$scape) #Create data frame for the mean size of ant eye\nprint(eye_mean) #Output the value in 'eye_mean', the mean size of the eye\n\n[1] NA\n\n\n\n# Test for Statistical Significance (Linear Model)\n\nmod_head = lm(head ~ altitude, data = Ant) #Creation of a linear model calculations for head measurements in relation to altitude\nsummary(mod_head) #Displaying the results of the linear model calculation \n\n\nCall:\nlm(formula = head ~ altitude, data = Ant)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75324 -0.29602 -0.04399  0.22126  2.37833 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.187e+00  3.613e-02  32.863  < 2e-16 ***\naltitude    -1.252e-04  2.663e-05  -4.701 2.92e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4098 on 1064 degrees of freedom\n  (13 observations deleted due to missingness)\nMultiple R-squared:  0.02035,   Adjusted R-squared:  0.01943 \nF-statistic:  22.1 on 1 and 1064 DF,  p-value: 2.925e-06\n\nmod_leg = lm(leg ~ altitude, data = Ant) #Creation of a linear model calculations for leg measurements in relation to altitude\nsummary(mod_leg) #Displaying the results of the linear model calculation \n\n\nCall:\nlm(formula = leg ~ altitude, data = Ant)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0824 -0.5439 -0.1428  0.5350  2.5360 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.486e+00  5.796e-02  25.646  < 2e-16 ***\naltitude    -2.368e-04  4.271e-05  -5.543 3.74e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6574 on 1064 degrees of freedom\n  (13 observations deleted due to missingness)\nMultiple R-squared:  0.02807,   Adjusted R-squared:  0.02716 \nF-statistic: 30.73 on 1 and 1064 DF,  p-value: 3.743e-08\n\nmod_scape = lm(scape~ altitude, data = Ant) #Creation of a linear model calculations for scape measurements in relation to altitude\nsummary(mod_scape) #Displaying the results of the linear model calculation \n\n\nCall:\nlm(formula = scape ~ altitude, data = Ant)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.84836 -0.40154 -0.08094  0.40349  2.33945 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.324e+00  4.402e-02  30.087  < 2e-16 ***\naltitude    -2.205e-04  3.244e-05  -6.796 1.78e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4993 on 1064 degrees of freedom\n  (13 observations deleted due to missingness)\nMultiple R-squared:  0.04161,   Adjusted R-squared:  0.04071 \nF-statistic: 46.19 on 1 and 1064 DF,  p-value: 1.783e-11\n\nmod_eye = lm(eye~ altitude, data = Ant) #Creation of a linear model calculations for eye measurements in relation to altitude\nsummary(mod_eye) #Displaying the results of the linear model calculation \n\n\nCall:\nlm(formula = eye ~ altitude, data = Ant)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.18512 -0.07062 -0.01803  0.06336  0.40555 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.343e-01  8.131e-03  28.814  < 2e-16 ***\naltitude    -2.227e-05  5.992e-06  -3.716 0.000213 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.09223 on 1064 degrees of freedom\n  (13 observations deleted due to missingness)\nMultiple R-squared:  0.01281,   Adjusted R-squared:  0.01189 \nF-statistic: 13.81 on 1 and 1064 DF,  p-value: 0.0002126\n\n# Result: All morphological features analyzed had a statistically significant relation to altitude (p-value < 0.05)\n\n\n# Figure Creation (Linear Regression)\n\n# Linear regression figure for eye size \nggplot(Ant,aes(x=altitude, y=eye)) + \n  geom_point() + \n  theme_classic() + #Change theme  for aesthetics \n  geom_smooth(method=\"lm\") + \n  labs(x='Altitude (in meters)', y='Logged Eye Size')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 13 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 13 rows containing missing values (`geom_point()`).\n\n\n\n\n# Linear regression figure for head size\nggplot(Ant,aes(x=altitude, y=head)) + \n  geom_point() + \n  theme_classic() + \n  geom_smooth(method=\"lm\") + \n  labs(x='Altitude (in meters)', y='Logged Head Size')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 13 rows containing non-finite values (`stat_smooth()`).\nRemoved 13 rows containing missing values (`geom_point()`).\n\n\n\n\n# Linear regression figure for leg size\nggplot(Ant,aes(x=altitude, y=leg)) + \n  geom_point() + \n  theme_classic() + \n  geom_smooth(method=\"lm\") + \n  labs(x='Altitude (in meters)', y='Logged Leg Size')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 13 rows containing non-finite values (`stat_smooth()`).\nRemoved 13 rows containing missing values (`geom_point()`).\n\n\n\n\n# Linear regression figure for scape size\nggplot(Ant,aes(x=altitude, y=scape)) + \n  geom_point() + \n  theme_classic() + \n  geom_smooth(method=\"lm\") + \n  labs(x='Altitude (in meters)', y='Logged Scape Size')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 13 rows containing non-finite values (`stat_smooth()`).\nRemoved 13 rows containing missing values (`geom_point()`).\n\n\n\n\n# Result: Four figures depicting the relationship of ant morphology to altitude"
  }
]